{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Sentimento "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste artigo será utilizado o algoritmo “Naive Bayes” é um classificador probabilístico baseado no “Teorema de Bayes”, a caracteristica mais proeminente deste algoritmo é o fato de que ele ignora a ligação de cada variável com outras, ou seja, em uma frase \"Eu sou Leonardo\" a frase pode ser separada da seguinte forma \"Eu\", \"sou\", \"Leonardo\", e cada trecho da frase se torna independente da outra. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Há outras maneiras de se dividir a frase também utilizando o conceito de n-grama, por exemplo se fosse utlizado na frase acima o bi-grama, a frase seria dividida da seguinte maneira: \"Eu sou\", \"sou Leonardo\". E essas duas partes continuam idependentes uma da outra. O fato de algoritmo não levar em conta as relações é o motivo pelo nome do algoritmo \"naive\" que significa ingênuo. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "arq = open('amazon_cells_labelled.txt', 'r')\n",
    "amazon = []\n",
    "amazonC = []\n",
    "for linha in arq:\n",
    "    frase = linha.replace('\\t', ' ').replace('\\n', '')\n",
    "    amazonC.append(frase[len(frase)-1])\n",
    "    frase = frase[0:len(frase)-2]\n",
    "    amazon.append(frase)\n",
    "arq.close()\n",
    "arq = open('imdb_labelled.txt', 'r')\n",
    "imdb = []\n",
    "imdbC = []\n",
    "for linha in arq:\n",
    "    frase = linha.replace('\\t', ' ').replace('\\n', '')\n",
    "    imdbC.append(frase[len(frase)-1])\n",
    "    frase = frase[0:len(frase) - 2]\n",
    "    imdb.append(frase)\n",
    "arq.close()\n",
    "arq = open('yelp_labelled.txt', 'r')\n",
    "yelp = []\n",
    "yelpC = []\n",
    "for linha in arq:\n",
    "    frase = linha.replace('\\t', ' ').replace('\\n', '')\n",
    "    yelpC.append(frase[len(frase)-1])\n",
    "    frase = frase[0:len(frase) - 2]\n",
    "    yelp.append(frase)\n",
    "arq.close()\n",
    "frases = amazon + imdb + yelp\n",
    "classes = amazonC + imdbC + yelpC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag Of Words\n",
    "O modelo bag-of-words é uma representação simplificada usada no processamento de linguagem natural e recuperação de informação (IR). Neste modelo, um texto (como uma frase ou um documento) é representado como o saco (multiset) de suas palavras, desconsiderando a gramática e até a ordem das palavras, mas mantendo a multiplicidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando CountVectorizers\n",
    "A primeira linha cria um objeto que irá vetorizar as frases as separando por palavra. A segunda linha utiliza o objeto criado contar as frequencias das palavras do IMDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer=\"word\")\n",
    "freq_imdb = vectorizer.fit_transform(imdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando o Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira linha cria o modelo com base no algoritmo Naive Bayes, a segunda linha utiliza as frequencias guardadas na variável *freq_imdb* e o sentimento de cada frase captado na leituras dos documentos e aplica o sentimento para cada palavra e calcula a probabilidade de aquela variavel ter conotação positiva ou negativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_imdb,imdbC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando o Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira linha transforma o conteúdo da variável *frases* em um bag of words, já na segunda linha o modelo tenta predizer o sentimento de cada frase, na última linha é impresso a porcentagem de acerto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grau de Acerto: 81.17%\n"
     ]
    }
   ],
   "source": [
    "freqFrases = vectorizer.transform(frases)\n",
    "resultados = modelo.predict(freqFrases)\n",
    "print('Grau de Acerto: {}%'.format(round(metrics.accuracy_score(classes, resultados)*100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melhorando o Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fazer isso iremos utilizar a técnica de Cross-Validation (Validação Cruzada), consiste em dividir todo o dado em K partes, chamadas de folds. Dessas partes uma será separada para teste e as outras restantes serão usadas para treinar o modelo. No próximo exemplo o corpus será dividido em 100. E podemos ver uma leve melhora e quantos mais partes dividirmos melhor será o resultado, porém será mais demorado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grau de Acerto: 82.8%\n"
     ]
    }
   ],
   "source": [
    "resultados = cross_val_predict(\n",
    "    modelo, freqFrases, classes, cv=100)\n",
    "print('Grau de Acerto: {}%'.format(round(metrics.accuracy_score(classes, resultados)*100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apesar do tamanho reduzido do corpus e a simplicidade do algoritmo, este retornou um bom resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliografia\n",
    "SANTANA, Rodrigo. **Análise de Sentimentos**: Aprenda de uma vez por todas como funciona utilizando dados do Twitter. 2017. Disponível em: <http://minerandodados.com.br/index.php/2017/03/15/analise-de-sentimentos-twitter-como-fazer/>. Acesso em: 18 jan. 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CANDIAGO, Lorenzo. **Algoritmo de Classificação Naive Bayes.** 2017. Disponível em: <https://www.organicadigital.com/seeds/algoritmo-de-classificacao-naive-bayes/>. Acesso em: 18 jan. 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOVELLO, Rafael. **Um pouco de Machine Learning com Python.** 2012. Disponível em: <https://imasters.com.br/back-end/um-pouco-de-machine-learning-com-python>. Acesso em: 18 jan. 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
